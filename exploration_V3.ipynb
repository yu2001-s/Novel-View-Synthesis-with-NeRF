{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.py', 'results', 'src', 'README.md', 'models', '.gitignore', 'wandb', 'exploration.ipynb', '.git', 'playground.ipynb', 'data', '.vscode', 'exploration_V3.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "P_PATH = os.getcwd()\n",
    "print(os.listdir(P_PATH))\n",
    "\n",
    "sys.path.append(P_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for training the NeRF model.\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from src.utils import *\n",
    "from src.data_loader import *\n",
    "from src.model import *\n",
    "from src.trainer import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shao-yu-huang/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set hyperparameters\n",
    "SCALEDOWN = 2\n",
    "OBJ_NAME = 'chair'\n",
    "BATCH_SIZE = 2048*2\n",
    "NUM_WORKERS = 8\n",
    "SAMPLE = 32 \n",
    "D = 6\n",
    "W = 128\n",
    "input_ch_pos = 3\n",
    "input_ch_dir = 2\n",
    "L_p = 10\n",
    "L_v = 4\n",
    "skips = [3]\n",
    "lr = 1e-3\n",
    "\n",
    "img_size = int(800/SCALEDOWN)\n",
    "\n",
    "# Set paths\n",
    "P_PATH = os.path.join(os.getcwd())\n",
    "sys.path.append(P_PATH)\n",
    "\n",
    "\n",
    "data_preprocess(OBJ_NAME, P_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_dataset = SynDatasetRay(obj_name=OBJ_NAME, root_dir=P_PATH, split='train', img_size=img_size, num_points=SAMPLE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "min_max = train_dataset.min_max\n",
    "\n",
    "val_dataset = SynDatasetRay(obj_name=OBJ_NAME, root_dir=P_PATH, split='val', img_size=img_size, num_points=SAMPLE, min_max=min_max)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "model = NeRF(D=D, W=W, input_ch_pos=input_ch_pos, input_ch_dir=input_ch_dir, skips=skips, L_p=L_p, L_v=L_v).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        # Unpack the data from the dataset\n",
    "        points = data['points'].to(device)\n",
    "        v_dir = data['v_dir'].to(device)\n",
    "        target_rgb = data['rgb'].to(device)\n",
    "        z_vals = data['z_vals'].to(device).squeeze(-1)  # Ensure z_vals are provided by the dataset\n",
    "\n",
    "        # Forward pass through the model\n",
    "        rgb, sigma = model(points, v_dir)\n",
    "\n",
    "        # Perform volume rendering using the outputs from the model\n",
    "        rendered_rgb = volume_rendering(z_vals, rgb, sigma, white_bkgd=False)\n",
    "\n",
    "        # Calculate the loss using the rendered RGB and the target RGB\n",
    "        loss = loss_fn(rendered_rgb, target_rgb)\n",
    "        print(loss.item())\n",
    "        total_loss += loss.item()\n",
    "average_loss = total_loss / len(val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
